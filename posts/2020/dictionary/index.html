<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Reverse-Engineering Apple Dictionary</title>

  <meta name="description" content="Personal webpage of Fabian Mentzer.">

  

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/posts/2020/dictionary/">

  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-169362627-1"></script>
  <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() { dataLayer.push(arguments); }
      gtag('js', new Date());

      gtag('config', 'UA-169362627-1');
  </script>
  
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
      <a href="/index.html#">
        
        <strong>Fabian</strong> Mentzer
      </a>
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/index.html#">About</a>
        <a class="page-link" href="/index.html#news">News</a>
        <a class="page-link" href="/index.html#pubs">Publications</a>
        <a class="page-link" href="/index.html#posts_overview">Posts</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Reverse-Engineering Apple Dictionary</h1>
    <p class="post-meta">December 8, 2020</p>
  </header>

  <article class="post-content">
    <p>For a while now I have wanted to write a simple dictionary app for the Apple
Watch. The goal was to be able to quickly look up words from paper books,
by storing the book on the watch to be able to do fuzzy matches against the text.
While Apple ships amazing dictionaries with macOS and iOS, they only provide a very
limited API.
On iOS, all you get is 
a <em>view</em> into the dictionary via <code class="language-plaintext highlighter-rouge">UIReferenceLibraryViewController</code>,
for the Watch, there is no API at all,
and on OS X you get an antique <code class="language-plaintext highlighter-rouge">DCSCopyTextDefinition</code> that only
returns a plain-text definition, which is not nice to display. The whole
definition is returned as one blob of non-rich text, no newlines.</p>

<p>It was while attempting to parse this output that I realized it would be so much
easier to get the source, which I’m showing here how to do.
I open-sourced this <a href="https://github.com/fab-jul/parse_dictionaries">on github</a>.</p>

<p>Here is a pic of the OS X dictionary:</p>

<p><img class="col three" src="/assets/img/dictionary.png" /></p>

<p>And here is what I managed to extract:</p>

<p><img class="col three" src="/assets/img/dictionary_watch.jpg" /></p>

<p>I started by trying to figure out where dictionaries are stored.
Some googling <a href="https://discussions.apple.com/thread/250861549?answerId=251679363022#251679363022">revealed</a>
that they are burried in <code class="language-plaintext highlighter-rouge">/System</code> 
(at least for macOS 10.15 and possibly higher), at</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/System/Library/AssetsV2/
  com_apple_MobileAsset_DictionaryServices_dictionaryOSX/
</code></pre></div></div>

<p>This folder contains various cryptically-named folders ending in <code class="language-plaintext highlighter-rouge">.asset</code>,
which represent the different installed dictionaries. E.g., for me:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ls
24effbf40402f823bb9d9f6f12b75af3e679a4a6.asset
26e585a43423edb02b25fa7ba9af3fdc08eed6d7.asset
4094df88727a054b658681dfb74f23702d3c985e.asset
96d637557afb292134db05d7d7f30c0fed9cef9f.asset
976258f0b1fad70dd8e7ee7c1b4be8f8536e19a7.asset
a1d5710e8c3932361413f22ff588a1a3c7c337bf.asset
com_apple_MobileAsset_DictionaryServices_dictionaryOSX.xml
</code></pre></div></div>

<p>Of these, <code class="language-plaintext highlighter-rouge">4094df88727a054b658681dfb74f23702d3c985e.asset</code> is the 
“New Oxford American Dictionary”. Going into that folder and
a few levels deeper, we land at a promisingly named “Resources” folder:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ls /System/Library/AssetsV2/
  com_apple_MobileAsset_DictionaryServices_dictionaryOSX/
  4094df88727a054b658681dfb74f23702d3c985e.asset/
  AssetData/
  New Oxford American Dictionary.dictionary/
  Contents/
  Resources/

Body.data        ca.lproj         ms.lproj
DefaultStyle.css cs.lproj         no.lproj
Dutch.lproj      da.lproj         pl.lproj
English.lproj    el.lproj         pt.lproj
EntryID.data     en_AU.lproj      pt_PT.lproj
EntryID.index    en_GB.lproj      ro.lproj
French.lproj     es_419.lproj     ru.lproj
German.lproj     fbm.css          sk.lproj
Images           fi.lproj         sv.lproj
Italian.lproj    fr_CA.lproj      th.lproj
Japanese.lproj   he.lproj         tr.lproj
KeyText.data     hi.lproj         uk.lproj
KeyText.index    hr.lproj         vi.lproj
NOAD.xsl         hu.lproj         zh_CN.lproj
Spanish.lproj    id.lproj         zh_HK.lproj
ar.lproj         ko.lproj         zh_TW.lproj
</code></pre></div></div>

<p>which is filled with a whole bunch of files. Sorting by size, it turns out
that <code class="language-plaintext highlighter-rouge">Body.data</code> could be a promising candidate at 23MB.</p>

<p>Sadly, it seems to be a binary blob without a discernible content.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ xxd Body.data | head -n15
00000000: 0000 0000 0000 0000 0000 0000 0000 0000  ................
00000010: 0000 0000 0000 0000 0000 0000 0000 0000  ................
00000020: 0000 0000 0000 0000 0000 0000 0000 0000  ................
00000030: 0000 0000 0000 0000 0000 0000 0000 0000  ................
00000040: f74d 7001 0000 0000 ffff ffff 2000 0000  .Mp......... ...
00000050: 0000 0000 da02 0000 ffff ffff ffff ffff  ................
00000060: 9480 0000 9080 0000 443b 0400 78da ecbd  ........D;..x...
00000070: 6b8c 2457 961e 26ed 6ab5 6fc9 300c c382  k.$W..&amp;.j.o.0...
00000080: 21e3 aac7 10ab b455 3df9 7eb0 67da aa6e  !......U=.~.g..n
00000090: 72d8 3d7c 0cc5 2667 b05a 8c1b 3723 6e66  r.=|..&amp;g.Z..7#nf
000000a0: 5c56 44dc e4bd 1155 9dc4 1a18 6261 9918  \VD....U....ba..
000000b0: 717f 505c db4b 2cb4 c66a e911 966b 4382  q.P\.K,..j...kC.
000000c0: b570 0bd6 2f75 f71a ae69 0c2c ff31 6003  .p../u...i.,.1`.
000000d0: b6e1 010c 0102 2c03 fee3 1f86 1fe7 dc1b  ......,.........
000000e0: 9195 8f88 cc8c c81b 9955 2407 c3ae aacc  .........U$.....
</code></pre></div></div>

<p>Scanning through the file with <code class="language-plaintext highlighter-rouge">xxd</code>, I did not find any visible structure.</p>

<p>However, given that the file is only ~23MB, I was thinking it may just be a ZIP file
in disguise.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>unzip Body.data
Archive:  Body.data
  End-of-central-directory signature not found.  Either this file is not
  a zipfile, or it constitutes one disk of a multi-part archive.  In the
  latter case the central directory and zipfile comment will be found on
  the last disk(s) of this archive.
unzip:  cannot find zipfile directory in one of Body.data or
        Body.data.zip, and cannot find Body.data.ZIP, period.
</code></pre></div></div>

<p>No luck! Same for <code class="language-plaintext highlighter-rouge">tar xvf</code>.</p>

<p>At this moment, I remembered
that the last time I had been thinking about this problem, years ago,
I had stumpled upon some cryptic C code. I remembered fiddling around with
XML, so I tried to dig up old projects, but sadly, I must have deleted them.</p>

<p>Some googling later, I stumpled upon the very <a href="https://gist.github.com/josephg/5e134adf70760ee7e49d">gist</a>
I had found years ago. It’s a very short and sweet python script to
extract entries from <code class="language-plaintext highlighter-rouge">Data.entry</code>. However, it’s also somewhat magical
in that it’s not documented, seeks random offsets, and even makes use
of the <code class="language-plaintext highlighter-rouge">struct</code> library.</p>

<p>But, it also does <code class="language-plaintext highlighter-rouge">import zlib</code>, so I thought, let’s try
to reverse engineer it myself.</p>

<p>The first simple
thing to try was to just attempt to find a ZIP file by going through the
bytes of the file one by one. After all,
it was very plausible that the file starts with some Apple
header followed by some compressed data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">zlib</span>
<span class="kn">import</span> <span class="nn">itertools</span>

<span class="n">DATA_FILE_PATH</span> <span class="o">=</span> <span class="o">...</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">DATA_FILE_PATH</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">content_bytes</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="c1"># Try all offsets to see if we find a ZIP file
</span><span class="k">for</span> <span class="n">offset</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">count</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s">'Trying {offset}...'</span><span class="p">)</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">content_decompressed</span> <span class="o">=</span> <span class="n">zlib</span><span class="o">.</span><span class="n">decompress</span><span class="p">(</span><span class="n">content_bytes</span><span class="p">[</span><span class="n">offset</span><span class="p">:])</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Found ZIP!'</span><span class="p">)</span>
    <span class="k">break</span>
  <span class="k">except</span> <span class="n">zlib</span><span class="o">.</span><span class="n">error</span><span class="p">:</span>  <span class="c1"># Current content_bytes is not a zipfile -&gt; skip a byte.
</span>    <span class="k">pass</span>
</code></pre></div></div>

<p>… and, low and behold, at byte number 108, a ZIP file starts!</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Trying 102...
Trying 103...
Trying 104...
Trying 105...
Trying 106...
Trying 107...
Trying 108...
Found ZIP!
</code></pre></div></div>

<p>Very exciting! What’s in this ZIP?</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; content_decompressed.decode()
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa3 in position 0: invalid start byte
</code></pre></div></div>

<p>Ok, so already the first byte cannot be decoded by ‘utf-8’, that’s a bit sad.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; print(content_decompressed[:20])
b'\xa3\x02\x00\x00&lt;d:entry xmlns:d'
</code></pre></div></div>

<p>Aha, already a few bytes later, some XML starts. For now, let’s just 
ignore the first four bytes.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; content_decompressed[4:].decode()
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe7 in position 2065: invalid continuation byte
</code></pre></div></div>

<p>That’s already more promising, we can decode 2065 bytes.
Looking around position 2065, we find:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt;&gt; print(content_decompressed[2055:2085])
b'an&gt;&lt;/d:entry&gt;\n\xe7\x02\x00\x00&lt;d:entry xml'
#              ^ |              |
#        newline |__ 4 bytes ___|
</code></pre></div></div>

<p>We see the entry ends, followed by a newline <code class="language-plaintext highlighter-rouge">\n</code>, some more
seemingly random bytes, and another entry starts!</p>

<p>For reference, here is the first entry (defining <code class="language-plaintext highlighter-rouge">007</code>, as it turns out):</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;d:entry</span> <span class="na">xmlns:d=</span><span class="s">"http://www.apple.com/DTDs/DictionaryService-1.0.rng"</span> 
    <span class="na">id=</span><span class="s">"m_en_gbus1179660"</span> 
    <span class="na">d:title=</span><span class="s">"007"</span> 
    <span class="na">class=</span><span class="s">"entry"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">"hg x_xh0"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;span</span> <span class="na">role=</span><span class="s">"text"</span> <span class="na">class=</span><span class="s">"hw"</span><span class="nt">&gt;</span>007 <span class="nt">&lt;/span&gt;</span>
  <span class="nt">&lt;/span&gt;</span>
  <span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">"sg"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;span</span> <span class="na">id=</span><span class="s">"m_en_gbus1179660.005"</span> <span class="na">class=</span><span class="s">"se1 x_xd0"</span><span class="nt">&gt;</span>
      <span class="nt">&lt;span</span> <span class="na">role=</span><span class="s">"text"</span> <span class="na">class=</span><span class="s">"posg x_xdh"</span><span class="nt">&gt;</span>
        <span class="nt">&lt;span</span> <span class="na">d:pos=</span><span class="s">"1"</span> <span class="na">class=</span><span class="s">"pos"</span><span class="nt">&gt;</span>
          <span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">"gp tg_pos"</span><span class="nt">&gt;</span>noun <span class="nt">&lt;/span&gt;</span>
          <span class="nt">&lt;d:pos/&gt;</span>
        <span class="nt">&lt;/span&gt;</span>
      <span class="nt">&lt;/span&gt;</span>
      <span class="nt">&lt;span</span> <span class="na">id=</span><span class="s">"m_en_gbus1179660.006"</span> <span class="na">class=</span><span class="s">"msDict x_xd1 t_core"</span><span class="nt">&gt;</span>
        <span class="nt">&lt;span</span> <span class="na">d:def=</span><span class="s">"1"</span> <span class="na">role=</span><span class="s">"text"</span> <span class="na">class=</span><span class="s">"df"</span><span class="nt">&gt;</span>
            the fictional British secret agent James Bond, or someone based on,
            inspired by, or reminiscent of him<span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">"gp tg_df"</span><span class="nt">&gt;</span>.<span class="nt">&lt;/span&gt;</span>
            <span class="nt">&lt;d:def/&gt;</span>
        <span class="nt">&lt;/span&gt;</span>
      <span class="nt">&lt;/span&gt;</span>
    <span class="nt">&lt;/span&gt;</span>
  <span class="nt">&lt;/span&gt;</span>
<span class="nt">&lt;/d:entry&gt;</span>
</code></pre></div></div>

<p>Exploring some more,
I did not find a pattern in these delimiter bytes except it always being
 4 bytes. I’m assuming they somehow tell you how long the next entry is.
 But we can just always ignore the 4 bytes and keep reading until the
 next newline appears.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">split</span><span class="p">(</span><span class="n">input_bytes</span><span class="p">):</span>
  <span class="c1"># The first four bytes are always not UTF-8.
</span>  <span class="n">input_bytes</span> <span class="o">=</span> <span class="n">input_bytes</span><span class="p">[</span><span class="mi">4</span><span class="p">:]</span>
  <span class="n">entries</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="c1"># Find the next newline, which delimits the current entry.
</span>    <span class="k">try</span><span class="p">:</span>
      <span class="n">next_offset</span> <span class="o">=</span> <span class="n">input_bytes</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">))</span>
    <span class="k">except</span> <span class="nb">ValueError</span><span class="p">:</span>  <span class="c1"># No more new-lines -&gt; no more entries!
</span>      <span class="k">break</span>
    <span class="n">entry_text</span> <span class="o">=</span> <span class="n">input_bytes</span><span class="p">[:</span><span class="n">next_offset</span><span class="p">]</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>
    <span class="n">entries</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entry_text</span><span class="p">)</span>

    <span class="c1"># There is always 4 bytes of chibberish between entries. Skip them
</span>    <span class="c1"># and the new lines (for a total of 5 bytes).
</span>    <span class="n">input_bytes</span> <span class="o">=</span> <span class="n">input_bytes</span><span class="p">[</span><span class="n">next_offset</span> <span class="o">+</span> <span class="mi">5</span><span class="p">:]</span>
  <span class="k">return</span> <span class="n">entries</span>
</code></pre></div></div>

<p>Aaaand… that yielded a measly 152 entries. Very sad. Where is the rest?
Let’s first see what entries we have:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>007, 2.0, 404, 420, 4D printing, 4K, 911, 999, a, a, A, A, a-, a-, a-, a-, -a, 
-a, -a, A1, A3, A4, A5, aa, AA, AAA, AAAS, Aachen, AAD, Aadhaar, Aalborg, Aalto, 
Alvar, AAM, A &amp; M, A &amp; R, aardvark, aardwolf, aargh, Aarhus, Aaron, Aaron, Hank,
Aaron's beard, Aaron's rod, AARP, AAU, AAUP, AAVE, abs, Ab, Ab, AB, AB, ab-, ABA,
 abaca, aback, abacus, Abadan, Abaddon, abaft, Abakan, abalone, abandon, abandoned,
abandonment, abandonware, abase, abasement, abash, abashed, abate, abatement, 
abattoir, a battuta, abaxial, abaya, Abba, Abba, abbacy, Abbas, Ferhat, Abbas,
Mahmoud, Abbasid, abbatial, abbé, abbess, Abbevillian, abbey, Abbey Road,
abbot, Abbott, Berenice, Abbott, Sir John, Abbott, Tony, abbr., abbreviate,
abbreviated, abbreviation, ABC, ABC, ABC, ABC Islands, ABD, abdicate,
abdication, abdomen, abdominal, abdominoplasty, abdominous, abducens, abducens
nerve, abduct, abductee, abduction, abductor, Abdul Hamid II, Abdul-Jabbar,
Kareem, Abdullah ibn Hussein, Abdullah II, Abdul Rahman, Tunku, Abe, Shinzo,
abeam, abecedarian, abed, abeer, Abel, Abel, Niels Henrik, Abelard, Peter,
abele, abelian, Abenomics, Abeokuta, Aberdeen, Aberdeen Angus, Aberdonian,
Abernathy, Ralph David, aberrant, aberration, Abertawe, abet, abettor,
abeyance, abhor, abhorrence, abhorrent, abide, abiding, Abidjan, Abilene,
ability, -ability, Abington, ab initio, abiogenesis
</code></pre></div></div>

<p>Clearly, we are doing something right, but we are just getting the very
first entries.</p>

<p>Going back to the first part, I realized that <code class="language-plaintext highlighter-rouge">content_decompressed</code>
is actually very short compared to all available bytes: Decompressing yielded
277kB of data, while the whole <code class="language-plaintext highlighter-rouge">Body.data</code> file is 24MB.</p>

<p>So, probably there more ZIP files. If so, how do we find them?
Obviously, we cannot just skip 277kB and try searching again,
as the compressed ZIP is smaller than 277kB. And blindly trying to do 
<code class="language-plaintext highlighter-rouge">zlib.decompress</code> at each possible offset takes forever (and is inelegant).</p>

<p>However, reading the <a href="https://docs.python.org/3/library/zlib.html">the zlib documentation</a>, it turns out that there 
is also a slightly fancier API. We can get a “Decompress” instance using
<code class="language-plaintext highlighter-rouge">zlib.decompressobj()</code>, call <code class="language-plaintext highlighter-rouge">decompress()</code> on that, and the instance
will actually return <code class="language-plaintext highlighter-rouge">unused_data</code>. (<strong>Very cool!</strong>)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">DATA_FILE_PATH</span><span class="p">,</span> <span class="s">'rb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
  <span class="n">content_bytes</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
  <span class="k">try</span><span class="p">:</span>
    <span class="n">decompressobj</span> <span class="o">=</span> <span class="n">zlib</span><span class="o">.</span><span class="n">decompressobj</span><span class="p">()</span>
    <span class="n">content_decompressed</span> <span class="o">=</span> <span class="n">decompressobj</span><span class="o">.</span><span class="n">decompress</span><span class="p">(</span><span class="n">content_bytes</span><span class="p">)</span>
    <span class="n">entries</span> <span class="o">=</span> <span class="n">split</span><span class="p">(</span><span class="n">content_decompressed</span><span class="p">)</span>
    <span class="c1"># In the next loop step, we use the unused data to look for a ZIP file.
</span>    <span class="n">content_bytes</span> <span class="o">=</span> <span class="n">decompressobj</span><span class="o">.</span><span class="n">unused_data</span>
  <span class="k">except</span> <span class="n">zlib</span><span class="o">.</span><span class="n">error</span><span class="p">:</span>  <span class="c1"># Current content_bytes is not a zipfile -&gt; skip a byte.
</span>    <span class="k">print</span><span class="p">(</span><span class="s">'Error, skipping a byte...'</span><span class="p">)</span>
    <span class="n">content_bytes</span> <span class="o">=</span> <span class="n">content_bytes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</code></pre></div></div>

<p>And this works. Turns out there is only 12 bytes after the first ZIP file
 before the next one starts, and then this pattern repeats for the
 rest of the file.</p>

<p>That’s (almost) all we need to parse the whole <code class="language-plaintext highlighter-rouge">Body.data</code>.
The only (minor) problem
was that the file ends with a bunch of meta information about the dictionary, 
which triggered some asserts in my code. But overall, with this, I was able
to extract definitions for 103013 words! Putting them all in a python <code class="language-plaintext highlighter-rouge">dict</code>
and <code class="language-plaintext highlighter-rouge">pickle</code>-ing this dict yields an impressive 200MB file. Zipping that file
yields again a ~24MB file.</p>

<p>What do we do with this? Well, it’s XML, which seems to be made mostly of HTML tags.
In the <code class="language-plaintext highlighter-rouge">Resources</code> folder, there is also <code class="language-plaintext highlighter-rouge">DefaultStyle.css</code>. Indeed,
wrapping the XML in some HTML boiler plate, including the style, and opening
the resulting file in Chrome yielded the following nice view:</p>

<p><img class="col three" src="/assets/img/dictionary_myoutput.png" /></p>

<h3 id="parsing-some-of-the-xml">Parsing some of the XML</h3>

<p>To actually use the parsed XML in a dictionary app for books, some further preprocessing
has to be done, to turn the input text into a list of definitions
that are actually found in the dictionary.</p>

<p>As a first step, I want to tokenize the text, i.e., split the text into words.
For example, I want to turn 
<code class="language-plaintext highlighter-rouge">"Nice doors", he said</code> into an array <code class="language-plaintext highlighter-rouge">[Nice, door, he, said]</code>. For this,
I used the Python Natural Language Toolkit, <a href="https://www.nltk.org">nltk</a>,
in particular it’s <code class="language-plaintext highlighter-rouge">word_toeknize</code> function:</p>

<pre><code class="language-jupyterpython">&gt;&gt;&gt; from nltk import tokenize
&gt;&gt;&gt; text = '"Nice door", he said.'
&gt;&gt;&gt; tokenize.word_tokenize(text)
['``', 'Nice', 'door', '"', ',', 'he', 'said']
</code></pre>

<p>It appeared that this does keep some punctuation in the words, so I did
some manual postprocessing:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">words</span> <span class="o">=</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="c1"># Remove punctuation in tokens, as ntlk tokenizes for example "they'll" as
# [they, 'll]. The resulting "ll" will be ditched in a later stage.
# Also removes tokens that are just quotes, which turn into empty tokens,
# removed at the MIN_WORD_LEN stage below.
</span><span class="n">words</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s">"'.-`</span><span class="se">\"</span><span class="s">"</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">)</span>
<span class="c1"># Ditches some genitives and third person singulars. In Python 3.9 this
# should be `removesuffix` but the `replace` works well enough in this context.
</span><span class="n">words</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s">"'s"</span><span class="p">,</span> <span class="s">''</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span><span class="p">)</span>
<span class="c1"># Removes abbreviations such as "e.g."
</span><span class="n">words</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="s">'.'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">w</span><span class="p">)</span>
<span class="c1"># Removes most punctuation from the list, such as ",", ":", etc.,
# also removes empty tokens.
</span><span class="n">MIN_WORD_LEN</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">MIN_WORD_LEN</span><span class="p">)</span>
<span class="c1"># Removes all numbers
</span><span class="n">words</span> <span class="o">=</span> <span class="p">(</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">isdigit</span><span class="p">()</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">w</span><span class="p">))</span>
</code></pre></div></div>

<p>The resulting list of words was then lemmatized with <code class="language-plaintext highlighter-rouge">WordNetLeammanizer</code>,
which turns, for example, <code class="language-plaintext highlighter-rouge">houses</code> into <code class="language-plaintext highlighter-rouge">house</code>. The lemmanizer
requires the caller to specify whether the word is an adjective, adverb, verb
or noun. Depending on this type, a word might be lemmanized differently.
I decided to just try all types for all words, and keep the lemmanized forms
if they are in the dictionary:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># First turn our list of words into a dictionary mapping words to how
# often they appear.
</span><span class="n">word_counts</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

<span class="n">word_dict</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># New Oxford American Dictionary as parsed above.
</span><span class="n">lemma</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>
<span class="n">word_counts_lemmad</span> <span class="o">=</span> <span class="n">collections</span><span class="o">.</span><span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">word_counts</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
  <span class="c1"># The possible lemmanized forms of the word `w`.
</span>  <span class="n">possible_words</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">wordnet</span><span class="o">.</span><span class="n">POS_LIST</span><span class="p">:</span>  <span class="c1"># where POS_LIST == [ADJ, ADV, VERB, NOUN]
</span>    <span class="n">w_lemmad</span> <span class="o">=</span> <span class="n">lemma</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">t</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">w_lemmad</span> <span class="o">!=</span> <span class="n">w</span><span class="p">:</span>
      <span class="n">possible_words</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">w_lemmad</span><span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">possible_words</span><span class="p">:</span>  <span class="c1"># No lemmanized form found, assume word itself.
</span>    <span class="n">possible_words</span> <span class="o">=</span> <span class="p">{</span><span class="n">w</span><span class="p">}</span>
  <span class="k">for</span> <span class="n">possible_w</span> <span class="ow">in</span> <span class="n">possible_words</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">possible_w</span> <span class="ow">in</span> <span class="n">word_dict</span><span class="p">:</span>
      <span class="n">word_counts_lemmad</span><span class="p">[</span><span class="n">possible_w</span><span class="p">]</span> <span class="o">+=</span> <span class="n">count</span>
</code></pre></div></div>

<p>I assume that there are better ways to process the text, and nltk seems
to have many more powerful functions, but the above code worked reasonably
well for my purpose.
The full preprocessing code can be found in <a href="https://github.com/fab-jul/parse_dictionaries/blob/main/extract.py">extract.py</a>.</p>

<p>Exploring the output, I realized a significant number of terms in the
input text was not found in the dictionary. 
For example, the noun <code class="language-plaintext highlighter-rouge">vitals</code> was not found in the dictionary,
as it hides in the definition of the adjective <code class="language-plaintext highlighter-rouge">vital</code>, and <code class="language-plaintext highlighter-rouge">vitals</code> is not 
lemmatized during preprocessing as the only valid base form is the noun <code class="language-plaintext highlighter-rouge">vitals</code>.
Thus, the above pre-processing will skip <code class="language-plaintext highlighter-rouge">vitals</code>, as it’s not in the <code class="language-plaintext highlighter-rouge">word_dict</code>.
Looking at the entry for the term <code class="language-plaintext highlighter-rouge">vital</code>, we see:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>vi·tal | ˈvīdl |
adjective
    1 absolutely necessary or important; essential : secrecy is of vital importance | it is vital that the system is regularly maintained .
    • indispensable to the continuance of life : the vital organs .
    2 full of energy; lively : a beautiful, vital girl .
    3 archaic fatal : the wound is vital .

noun ( vitals )
    the body's important internal organs, especially the gut or the genitalia : he felt the familiar knot contract in his vitals .
    • short for vital signs.
</code></pre></div></div>

<p>In the second definition, we find the term <code class="language-plaintext highlighter-rouge">vitals</code>. Looking at the XML,
we see:</p>

<div class="language-xml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">"x_xdh"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;span</span> <span class="na">role=</span><span class="s">"text"</span> <span class="na">class=</span><span class="s">"posg"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;span</span> <span class="na">d:pos=</span><span class="s">"2"</span> <span class="na">class=</span><span class="s">"pos"</span><span class="nt">&gt;</span>
      <span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">"gp tg_pos"</span><span class="nt">&gt;</span>noun <span class="nt">&lt;/span&gt;</span>
      <span class="nt">&lt;d:pos/&gt;</span>
    <span class="nt">&lt;/span&gt;</span>
  <span class="nt">&lt;/span&gt;</span>
  <span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">"fg"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">"gp tg_fg"</span><span class="nt">&gt;</span>(<span class="nt">&lt;/span&gt;</span>
    <span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">"f"</span><span class="nt">&gt;</span>vitals<span class="nt">&lt;/span&gt;</span>  <span class="c">&lt;!-- the desired term! --&gt;</span>
    <span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">"gp tg_fg"</span><span class="nt">&gt;</span>) <span class="nt">&lt;/span&gt;</span>
  <span class="nt">&lt;/span&gt;</span>
<span class="nt">&lt;/span&gt;</span>
<span class="nt">&lt;span</span> <span class="na">id=</span><span class="s">"m_en_gbus1132680.014"</span> <span class="na">class=</span><span class="s">"msDict x_xd1 t_core"</span><span class="nt">&gt;</span>
  <span class="nt">&lt;span</span> <span class="na">d:def=</span><span class="s">"2"</span> <span class="na">role=</span><span class="s">"text"</span> <span class="na">class=</span><span class="s">"df"</span><span class="nt">&gt;</span>the body's important internal organs, especially the gut or the genitalia<span class="nt">&lt;d:def/&gt;&lt;/span&gt;</span>
  <span class="nt">&lt;span</span> <span class="na">role=</span><span class="s">"text"</span> <span class="na">class=</span><span class="s">"gp tg_df"</span><span class="nt">&gt;</span>: <span class="nt">&lt;/span&gt;</span>
  <span class="nt">&lt;span</span> <span class="na">role=</span><span class="s">"text"</span> <span class="na">class=</span><span class="s">"eg"</span><span class="nt">&gt;</span>
    <span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">"ex"</span><span class="nt">&gt;</span> he felt the familiar knot contract in his vitals<span class="nt">&lt;/span&gt;</span>
    <span class="nt">&lt;span</span> <span class="na">class=</span><span class="s">"gp tg_eg"</span><span class="nt">&gt;</span>. <span class="nt">&lt;/span&gt;</span>
  <span class="nt">&lt;/span&gt;</span>
  <span class="nt">&lt;span</span> <span class="na">role=</span><span class="s">"text"</span> <span class="na">class=</span><span class="s">"gp tg_msDict"</span><span class="nt">&gt;</span> <span class="nt">&lt;/span&gt;</span>
<span class="nt">&lt;/span&gt;</span>
</code></pre></div></div>

<p>I created the following XPath to locate these terms</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">XPATH_OTHER_WORDS</span> <span class="o">=</span> <span class="s">'//span[@class="fg"]/span[@class="f"]'</span>
</code></pre></div></div>

<p>Trying the XPath on all definitions seemed to uncover a lot of additional terms.
Mostly, these are plurals or phrasal verbs (the
definition of <code class="language-plaintext highlighter-rouge">act</code> contains <code class="language-plaintext highlighter-rouge">act on</code>, <code class="language-plaintext highlighter-rouge">act for</code>, etc.),
but this helped find some words in my input text.</p>

<p>On a side note, I learned during this project that Chrome has a really great
way to test XPath queries (while writing I realized Safari actually also has this).
Right Click -&gt; “Inspect”, CMD+F, note the search bar at the bottom
of the window:</p>

<p><img class="col three" src="/assets/img/xpath_chrome.png" /></p>

<p>You can even select XML elements and Right Click -&gt; Copy -&gt; XPath to extract
a somewhat verbose XPath.</p>

<p>Going back to the definitions, I wrote a second XPath to get derivative 
definitions. It turns out a lot of terms hide there, in particular adverbs, but also a 
lot of derived nouns. An example entry with useful derivatives:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>snoop | sno͞op | informal
verb [no object]
    investigate or look around furtively [...]
noun [in singular]
    a furtive investigation [...]

DERIVATIVES
    snooper | ˈsno͞opər | noun
    snoopy adjective
</code></pre></div></div>

<p>Overall, this allowed me to find most words in my input text. The 
remaining terms were mostly names or book-specific jargon.</p>

<h3 id="getting-it-onto-the-apple-watch">Getting it onto the Apple Watch</h3>

<p>I wanted to look at these entries on the Watch. Sadly, it turns out there
is no <code class="language-plaintext highlighter-rouge">UIWebView</code> (used to render HTML in iOS) in WatchKit. But, 
<code class="language-plaintext highlighter-rouge">NSAttributedString</code> can be constructed from a HTML string. As it turns out,
it can even contain CSS, as long as the CSS is inlined in the HTML as a
<code class="language-plaintext highlighter-rouge">&lt;style&gt;</code> element in the header.</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">let</span> <span class="nv">HTML_ENTRY_START</span> <span class="o">=</span> <span class="s">"""
 &lt;html lang="</span><span class="n">en</span><span class="s">"&gt;
 &lt;head&gt;
   &lt;meta charset="</span><span class="n">utf</span><span class="o">-</span><span class="mi">8</span><span class="s">"&gt;
   &lt;title&gt;Words&lt;/title&gt;
   &lt;style&gt;
      ... Full DefaultStyle.css file here ...
   &lt;/style&gt;
  &lt;/head&gt;
  &lt;body&gt;
"""</span>
<span class="k">let</span> <span class="nv">HTML_ENTRY_END</span> <span class="o">=</span> <span class="s">"&lt;/body&gt;"</span>

<span class="k">let</span> <span class="nv">definition</span><span class="p">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">...</span> <span class="c1">// The XML</span>
<span class="k">let</span> <span class="nv">htmlDefinition</span> <span class="o">=</span> <span class="kt">HTML_ENTRY_START</span> <span class="o">+</span> <span class="n">definition</span> <span class="o">+</span> <span class="kt">HTML_ENTRY_END</span>
<span class="k">let</span> <span class="nv">data</span> <span class="o">=</span> <span class="n">htmlDefinition</span><span class="o">.</span><span class="nf">data</span><span class="p">(</span><span class="nv">using</span><span class="p">:</span> <span class="o">.</span><span class="n">utf8</span><span class="p">)</span><span class="o">!</span>
<span class="k">let</span> <span class="nv">attributedDefinition</span> <span class="o">=</span> <span class="k">try</span> <span class="kt">NSAttributedString</span><span class="p">(</span>
    <span class="nv">data</span><span class="p">:</span> <span class="n">data</span><span class="p">,</span>
    <span class="nv">options</span><span class="p">:</span> <span class="p">[</span><span class="o">.</span><span class="nv">documentType</span><span class="p">:</span> <span class="kt">NSAttributedString</span><span class="o">.</span><span class="kt">DocumentType</span><span class="o">.</span><span class="n">html</span><span class="p">],</span>
    <span class="nv">documentAttributes</span><span class="p">:</span> <span class="kc">nil</span><span class="p">)</span>
<span class="n">outputLabel</span><span class="o">.</span><span class="nf">setAttributedText</span><span class="p">(</span><span class="n">attributedDefinition</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="conclusion">Conclusion</h3>

<p>This was a fun little exercise in reverse engineering. I’m not sure I would
have gone through this had I not found the gist and seen <code class="language-plaintext highlighter-rouge">import zlib</code>,
as before that, the file looked very daunting. However, seeing that import
statement gave the necessary energy to just push a bit further,
and the rest was mostly a breeze.</p>

  </article>

  

</div>

      </div>
    </div>

    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">



  </body>

</html>
